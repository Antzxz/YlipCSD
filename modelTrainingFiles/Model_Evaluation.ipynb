{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation script was utilize to evaluate performance on test data.\n",
    "\n",
    "### Inputs:\n",
    "* Final trained model to be evaluated (Created in ML_Pipeline_part4).\n",
    "* Encoded data in the form of a pickle file (created in ML_Pipeline_part1,ML_Pipeline_part2,ML_Pipeline_part3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell imports libraries necessary for the model.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,ShuffleSplit\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import ElasticNet,Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern, RBF,WhiteKernel, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,AdaBoostRegressor, ExtraTreesRegressor,BaggingRegressor\n",
    "from mlxtend.regressor import StackingRegressor,StackingCVRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split, validation_curve,GridSearchCV,learning_curve,cross_val_score,KFold\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from scipy.stats import pearsonr, linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R squared function.\n",
    "def rsquared(y_true, y_pred):\n",
    "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(y_true, y_pred)\n",
    "    return r_value**2\n",
    "\n",
    "#mean absolute percent error.\n",
    "def MAPE(y_true,y_pred):\n",
    "    y_true,y_pred = np.array(y_true),np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true-y_pred) /y_true)) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting serperate individual values\n",
    "def example_plot(ax,name2,group2,title2):\n",
    "        temp1= np.max([group['actual'].max(),group['prediction'].max()])\n",
    "        pr = pearsonr(group['prediction'],group['actual'])\n",
    "\n",
    "        text = '\\nMAE: '+str(Decimal(str(mae(group['prediction'],group['actual']))).quantize(Decimal('.01')))+'\\nR: '+str(Decimal(str(pr[0])).quantize(Decimal('0.01')))#+'\\nMSE:'+str(Decimal(str(mse(group['prediction'],group['actual']))).quantize(Decimal('0.001')))\n",
    "        text = '\\nMAE: '+str(Decimal(str(mae(group['prediction'],group['actual']))).quantize(Decimal('.01')))+'\\nR2: '+str(Decimal(str(rsquared(group['prediction'],group['actual']))).quantize(Decimal('0.01')))#+'\\nMSE:'+str(Decimal(str(mse(group['prediction'],group['actual']))).quantize(Decimal('0.001')))\n",
    "        if temp1 < 1:\n",
    "            temp1+=.05\n",
    "            lineData = np.arange(0,temp1,.01)\n",
    "        elif temp1 <75:\n",
    "            temp1+=1.5\n",
    "            lineData = np.arange(0,temp1)\n",
    "        else:\n",
    "            temp1+=3\n",
    "            lineData = np.arange(0,temp1)\n",
    "        ax.plot(lineData,lineData,color='red')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(name2,fontsize=18)\n",
    "        ax.text(0.2,0.9,text,horizontalalignment='center',verticalalignment='center',transform=ax.transAxes,fontsize=15)\n",
    "        ax.plot(group2['actual'],group2['prediction'], marker='.',linestyle='',ms=12)\n",
    "        ax.set_ylabel('Prediction (g/L)',size=15)\n",
    "        ax.set_xlabel('Experimental (g/L)',size=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that the encoded data & final pickle model to be evaluated or used for predictions are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the test data for model evaluation\n",
    "with open ('TESTData_part3.pickle','rb') as f:\n",
    "    encodedData = pickle.load(f)    \n",
    "\n",
    "#loading the model for evaluation    \n",
    "with open('M21iYL.pickle','rb') as f:\n",
    "    masterGrid = pickle.load(f)   \n",
    "    \n",
    "    \n",
    "masterGrid = masterGrid[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features in the model.\n",
    "cols_train__set = [\n",
    "'mw_Lipids'\n",
    ",'pH'\n",
    ",'product_deltaGo'\n",
    ",'foldCarbonFed'\n",
    ",'product_name'\n",
    ",'rxt_volume'\n",
    ",'inputThermo(kJ/L)'\n",
    ",'FermentationTime'\n",
    ",'atp_cost'\n",
    ",'precursorsRequiredEncoded'\n",
    ",'nadh_nadph_cost'\n",
    ",'Pathway_enzymatic_steps'\n",
    ",'averageThermBarrier'\n",
    ",'media'\n",
    ",'number_genes_het'\n",
    ",'number_native_genes_overexp'\n",
    ",'ATP_iYLI647'\n",
    ",'NADPH_iYLI647'\n",
    ",'PPP_iYLI647'\n",
    ",'TCA_iYLI647'\n",
    ",'PrdtYield_iYLI647'\n",
    "    \n",
    ",'Product_titer(g/L)'\n",
    ",'Product_rate(g/L/h)'\n",
    ",'Product_yield(g/gC)'\n",
    "]\n",
    "\n",
    "\n",
    "target_cols_todrop = [\n",
    "'Product_yield(g/gC)'\n",
    ",'Product_rate(g/L/h)'\n",
    ",'Product_titer(g/L)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdt_class = np.arange(1,10)\n",
    "product_superclass = ['Organic acid', 'Lipid','Small terpene','Large terpene','Flavonoid','Fatty acid-derived','Alcohol','Glycan','Polyketide']\n",
    "# productsToTestCases = ['a-Ionone', 'Mevalonate', 'Campersterol', 'a-Farnesene', '1-decanol','Arachidonic acid']\n",
    "\n",
    "productDict = dict(zip(prdt_class,product_superclass))\n",
    "\n",
    "scaledData = pd.DataFrame()\n",
    "scaledData = encodedData[0]\n",
    "\n",
    "# heldOutTest = pd.DataFrame()\n",
    "\n",
    "temp = []\n",
    "for p in productsToTestCases:\n",
    "    temp = scaledData[scaledData.product_name2 == p]\n",
    "    tempIndex = scaledData[scaledData.product_name2 ==p].index\n",
    "#     heldOutTest = heldOutTest.append(temp)\n",
    "\n",
    "useful_cols = []\n",
    "useful_cols.extend(cols_train__set)\n",
    "\n",
    "data = scaledData.loc[:,useful_cols]\n",
    "\n",
    "for column in data:\n",
    "    data[column] = data[column].astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment following line to test validate, training split. For test data, comment line.\n",
    "# train, test = train_test_split(data, test_size = 0.20, random_state = 566,stratify=data['product_name'])\n",
    "\n",
    "test = data #comment out if want to use validate, training data, generated in line above\n",
    "train = data #comment out if want to use validate, training data, generated in line above\n",
    "x_train = train.copy()\n",
    "x_test = test.copy()\n",
    "y_test = test.copy()\n",
    "\n",
    "# for dummy variable models, will expand the following features into a dummy variable\n",
    "toCont = ['product_name']\n",
    "\n",
    "# drop the target from the datasets\n",
    "for target1 in target_cols_todrop:\n",
    "    x_train.drop(target1,axis=1,inplace=True)\n",
    "    x_test.drop(target1,axis=1,inplace=True)\n",
    "x_testData = x_test.copy()\n",
    "target = 'Product_titer(g/L)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the model prediction (model predicts the log value of the output)\n",
    "y_prediction = np.exp(masterGrid[target].predict(x_testData))\n",
    "# the actual output value\n",
    "y_actual = y_test[target]\n",
    "\n",
    "pr = pearsonr(y_prediction,y_actual)\n",
    "\n",
    "print('For ' + target)\n",
    "print('***************************************')\n",
    "print('r2:\\n',rsquared(y_prediction,y_actual),'\\nMAE:\\n',mae(y_prediction,y_actual),'\\nMSE\\n',mse(y_prediction,y_actual),'\\nPearson R\\n',pearsonr(y_prediction,y_actual),'\\nMAPE\\n',MAPE(y_actual,y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure save name\n",
    "save_name = 'M21iYL_1200.eps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following cell generates a figure with the line of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "'Product_titer(g/L)'\n",
    "]\n",
    "\n",
    "title = 'Total Set'\n",
    "i=0\n",
    "for target in target_cols:\n",
    "  \n",
    "    #obtain the model prediction (model predicts the log value of the output)\n",
    "    y_prediction = np.exp(masterGrid[target].predict(x_testData))\n",
    "    # the actual output value\n",
    "    y_actual = y_test[target]\n",
    "    \n",
    "    print('For ' + target)\n",
    "    print('***************************************')\n",
    "    \n",
    "    pr = pearsonr(y_prediction,y_actual)\n",
    "\n",
    "    print('r2:\\n',rsquared(y_prediction,y_actual),'\\nMAE:\\n',mae(y_prediction,y_actual),'\\nMSE\\n',mse(y_prediction,y_actual),'\\nPearson R\\n',pearsonr(y_prediction,y_actual))\n",
    "\n",
    "    text = '\\nMAE: '+str(Decimal(str(mae(y_prediction,y_actual))).quantize(Decimal('.01')))+'  \\nR2: '+str(Decimal(str(rsquared(y_prediction,y_actual))).quantize(Decimal('0.01')))\n",
    "    # i+=1\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(15)\n",
    "    ax.margins(0.05)\n",
    "    y_hat=pd.DataFrame()\n",
    "\n",
    "    y_hat['prediction']=y_prediction\n",
    "    y_hat.index=y_actual.index\n",
    "    y_hat['actual']=y_actual\n",
    "    y_hat['productClass']=x_testData['product_name']\n",
    "    y_hat['superClass']=x_testData['product_name'].map(productDict)\n",
    "\n",
    "    temp1= max(np.max(y_actual),np.max(y_prediction))\n",
    "\n",
    "    lineData = np.arange(0,temp1)\n",
    "    groups = y_hat.groupby('superClass')\n",
    "    for name, group in groups:\n",
    "\n",
    "        ax.plot(group['actual'],group['prediction'], marker='.',linestyle='',ms=12,label=name)\n",
    "\n",
    "    ax.legend(loc=2,ncol=3,fontsize=16)\n",
    "    ax.text(0.1,0.8,text,horizontalalignment='center',verticalalignment='center',transform=ax.transAxes,fontsize=20)\n",
    "    ax.set_ylabel('Prediction',size=24)\n",
    "    ax.set_xlabel('Experimental',size=24)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    plt.savefig(save_name,format='eps',dpi=1200,bbox_inches='tight')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following cell generates a 3 x 3 grid of figures for each product class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testData = x_test.copy()\n",
    "i=0\n",
    "for target in target_cols:\n",
    "    #obtain the model prediction (model predicts the log value of the output)\n",
    "    y_prediction = np.exp(masterGrid[target].predict(x_testData))\n",
    "    # the actual output value\n",
    "    y_actual = y_test[target]\n",
    "    \n",
    "    print('For ' + target)\n",
    "    print('***************************************')\n",
    "    \n",
    "    pr = pearsonr(y_prediction,y_actual)\n",
    "    print('R:\\n',rsquared(y_prediction,y_actual),'\\nMAE:\\n',mae(y_prediction,y_actual),'\\nMSE\\n',mse(y_prediction,y_actual),'\\nPearsonR:',pr)\n",
    "\n",
    "    y_hat=pd.DataFrame()\n",
    "    y_hat['prediction']=y_prediction\n",
    "    y_hat.index=y_actual.index\n",
    "    y_hat['actual']=y_actual\n",
    "    y_hat['productClass']=x_testData['product_name']\n",
    "    y_hat['superClass']=x_testData['product_name'].map(productDict)\n",
    "    groups = y_hat.groupby('superClass')\n",
    "    k=1\n",
    "    fig, axes = plt.subplots(3,3,figsize=(20,20))\n",
    "    axes2 = axes.flatten()\n",
    "    \n",
    "    \n",
    "    for name, group in groups:\n",
    "        example_plot(axes2[k-1],name,group,title)\n",
    "        k+=1\n",
    "    plt.savefig('3by3'+save_name,format='eps',dpi=1200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPY36",
   "language": "python",
   "name": "condapy36lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
