{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate feature score importance\n",
    "\n",
    "## Detailed in \"Integrated data mining, genome-scale modeling, and machine learning for predicting yeast bioproduction\"\n",
    "\n",
    "### Description: Script takes a ML trained model (see ML_Pipeline files) and a dataset (test, validate or training set) and evaluates the accuracy. \n",
    "\n",
    "#### Procedure:\n",
    "1. Shuffle the values in each feature. Exampe ATP Cost unshuffled values [1,2,6,8,...,10] --> shuffled [2,8,2,10,...,6]\n",
    "2. Evalute the prediction accuracy with the shuffled features.\n",
    "3. Repeat 1000 times.\n",
    "4. Average each accuracy prediction to obtain the importance score.\n",
    "\n",
    "#### Inputs:\n",
    "1. Trained ML model object\n",
    "2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import ElasticNet,Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import xgboost as xgb\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,FunctionTransformer\n",
    "from decimal import Decimal, ROUND_DOWN\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from scipy.stats import pearsonr, linregress\n",
    "from sklearn.model_selection import train_test_split, validation_curve,GridSearchCV,learning_curve,cross_val_score,KFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "from sklearn.metrics import mean_poisson_deviance as MPD\n",
    "from sklearn.metrics import mean_gamma_deviance as MGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsquared(y_true, y_pred):\n",
    "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(y_true, y_pred)\n",
    "    return r_value**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data file inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trained ML object\n",
    "with open('M21iYL.pickle','rb') as f:\n",
    "    masterGrid = pickle.load(f)\n",
    "    \n",
    "## Encoded Dataset \n",
    "with open ('TESTData_part3.pickle','rb') as f:\n",
    "    encodedData = pickle.load(f)    \n",
    "\n",
    "scaledData = encodedData[0]\n",
    "scaledData['thermo(kJ/g)'] = scaledData['inputThermo(kJ/L)']/scaledData['csConcTotal']\n",
    "\n",
    "masterGrid = masterGrid[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features used from data set in final model\n",
    "# Used features in the final model.\n",
    "cols_train__set = [\n",
    "# 'dir_evo'\n",
    "# ,'number_genes_deleted'\n",
    "# ,'reactor_type'\n",
    "'mw_Lipids'\n",
    ",'pH'\n",
    "# ,'product_deltaG\\'o'\n",
    ",'product_deltaGo'\n",
    ",'foldCarbonFed'\n",
    ",'product_name'\n",
    "# ,'number_total_genes_overexp'\n",
    "# ,'promoterEncoded(Sum)'\n",
    ",'rxt_volume'\n",
    "# ,'N2SourceEncoded(mean)'\n",
    "# ,'N2SourceEncoded(max)'\n",
    "# ,'N2_content'\n",
    "# ,'N2_contentEncoded'\n",
    ",'inputThermo(kJ/L)'\n",
    "# ,'number_genes_mod'\n",
    "# ,'strain_background'\n",
    "# ,'oxygen'\n",
    ",'FermentationTime'\n",
    ",'atp_cost'\n",
    ",'precursorsRequiredEncoded'\n",
    "# ,'ccmPrecursorToProduct(FA)'###########\n",
    ",'nadh_nadph_cost'\n",
    ",'Pathway_enzymatic_steps'\n",
    "#,'no_c'\n",
    "# ,'ccm_precursor_deltaGo'\n",
    ",'averageThermBarrier'\n",
    "# ,'totalThermBarrier'\n",
    "# ,'csConcTotal'\n",
    ",'media'\n",
    ",'number_genes_het'\n",
    ",'number_native_genes_overexp'\n",
    "# ,'integrationSiteEncoded(Sum)'\n",
    "\n",
    ",'Product_titer(g/L)'\n",
    ",'Product_rate(g/L/h)'\n",
    ",'Product_yield(g/gC)'#,\n",
    "\n",
    " ,'ATP_iYLI647'\n",
    " ,'NADPH_iYLI647'\n",
    " # ,'EMP_iYLI647'\n",
    " ,'PPP_iYLI647'\n",
    " ,'TCA_iYLI647'\n",
    " , 'PrdtYield_iYLI647'\n",
    " # ,'O2Uptake_iYLI647'\n",
    " # ,'Biomass_iYLI647'\n",
    "]\n",
    "\n",
    "\n",
    "# targets for ML, drop from feature list before training.\n",
    "target_cols_todrop = [\n",
    "'Product_yield(g/gC)'\n",
    ",'Product_rate(g/L/h)'\n",
    ",'Product_titer(g/L)'\n",
    "]\n",
    "\n",
    "\n",
    "useful_cols = []\n",
    "useful_cols.extend(cols_train__set)\n",
    "data = scaledData.loc[:,useful_cols]\n",
    "\n",
    "for column in data:\n",
    "    data[column] = data[column].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for evaluating models trained with dummy variables for the product class\n",
    "\n",
    "# 0 - no \n",
    "# 1 - yes\n",
    "dummyOption = 0\n",
    "\n",
    "#drop the dummy variables from the output metric list\n",
    "dummy_drop = ['product_name','Product_titer(g/L)','Product_rate(g/L/h)','Product_yield(g/gC)']\n",
    "dummy_cols_train__set = list(set(cols_train__set)-set(dummy_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment following line to test validate, training split. For test data, comment line.\n",
    "# train, test = train_test_split(data, test_size = 0.20, random_state = 566,stratify=data['product_name'])\n",
    "\n",
    "test = data #comment out if want to use validate, training data, generated in line above\n",
    "train = data #comment out if want to use validate, training data, generated in line above\n",
    "x_train = train.copy()\n",
    "x_test = test.copy()\n",
    "y_test = test.copy()\n",
    "\n",
    "if dummyOption == 1:\n",
    "    toCont = ['product_name']\n",
    "    x_train = pd.get_dummies(train,columns=toCont)\n",
    "    x_test = pd.get_dummies(test,columns=toCont)\n",
    "    y_test = pd.get_dummies(test,columns=toCont)\n",
    "\n",
    "# Drop the output metrics from training set.\n",
    "for target1 in target_cols_todrop:\n",
    "    x_train.drop(target1,axis=1,inplace=True)\n",
    "    x_test.drop(target1,axis=1,inplace=True)\n",
    "\n",
    "\n",
    "x_testData = x_test.copy()\n",
    "target = 'Product_titer(g/L)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the storage for the output metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_ = defaultdict(list)\n",
    "rsquareds = defaultdict(list)\n",
    "r2_improvement = defaultdict(list)\n",
    "r2_improvement_percent = defaultdict(list)\n",
    "mse_ = defaultdict(list)\n",
    "mae_ = defaultdict(list)\n",
    "mae_scores = defaultdict(list)\n",
    "mae_improvement = defaultdict(list)\n",
    "mae_improvement_percent = defaultdict(list)\n",
    "number_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n",
      "50\n",
      "75\n",
      "100\n",
      "125\n",
      "150\n",
      "175\n",
      "200\n",
      "225\n",
      "250\n",
      "275\n",
      "300\n",
      "325\n",
      "350\n",
      "375\n",
      "400\n",
      "425\n",
      "450\n",
      "475\n",
      "500\n",
      "525\n",
      "550\n",
      "575\n",
      "600\n",
      "625\n",
      "650\n",
      "675\n",
      "700\n",
      "725\n",
      "750\n",
      "775\n",
      "800\n",
      "825\n",
      "850\n",
      "875\n",
      "900\n",
      "925\n",
      "950\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "#generate the initial reuslts\n",
    "\n",
    "y_prediction = np.exp(masterGrid[target].predict(x_testData))\n",
    "y_actual = y_test[target]\n",
    "r2_acc = rsquared(y_prediction,y_actual)\n",
    "mae_acc = mae(y_prediction,y_actual)\n",
    "mse_acc = mse(y_prediction,y_actual)\n",
    "\n",
    "#were dummy variables used?\n",
    "if dummyOption==0:\n",
    "    \n",
    "    #list of features to sort through\n",
    "    names=list(x_testData)\n",
    "    \n",
    "    #shuffle through features 1000 times\n",
    "    for iterations in range(0,1000):\n",
    "        #shuffle through each feature\n",
    "        for w in range(x_testData.shape[1]):\n",
    "            \n",
    "            #copy of the initial data\n",
    "            x_t = x_testData.copy() \n",
    "            \n",
    "            #random permutation of values\n",
    "            x_t[names[w]]= np.random.permutation(x_t[names[w]].values)\n",
    "\n",
    "            #prediction and metrics\n",
    "            prediction = np.exp(masterGrid[target].predict(x_t))\n",
    "            r2_shuff_acc = rsquared(y_actual, prediction)\n",
    "            r2_[names[w]] = r2_shuff_acc\n",
    "            rsquareds[names[w]].append(abs((r2_acc-r2_shuff_acc)/r2_acc))\n",
    "            mae_shuff_acc = mae(y_actual,prediction)\n",
    "            mae_[names[w]] = mae_shuff_acc\n",
    "            mae_scores[names[w]].append(abs((mae_acc-mae_shuff_acc)/mae_acc))\n",
    "            mse_shuff_acc = mse(y_actual,prediction)\n",
    "            mse_[names[w]] = mse_shuff_acc\n",
    "\n",
    "        if (iterations%25)==0:\n",
    "            print (iterations)\n",
    "else:\n",
    "    \n",
    "    #shuffle through features 1000 times    \n",
    "    for iterations in range(0,1000):\n",
    "        \n",
    "        #shuffle through each feature\n",
    "        for w in dummy_cols_train__set:\n",
    "\n",
    "            #copy of the initial data\n",
    "            x_t = x_testData.copy()\n",
    "\n",
    "            #random permutation of values\n",
    "            x_t[[w]]= np.random.permutation(x_t[[w]].values)\n",
    "\n",
    "            #prediction and metrics\n",
    "            prediction = np.exp(masterGrid[target].predict(x_t))\n",
    "            r2_shuff_acc = rsquared(y_actual, prediction)\n",
    "            r2_[str(w)] = r2_shuff_acc\n",
    "            rsquareds[str(w)].append(abs((r2_acc-r2_shuff_acc)/r2_acc))\n",
    "            mae_shuff_acc = mae(y_actual,prediction)\n",
    "            mae_[str(w)] = mae_shuff_acc\n",
    "            mae_scores[str(w)].append(abs((mae_acc-mae_shuff_acc)/mae_acc))\n",
    "            mse_shuff_acc = mse(y_actual,prediction)\n",
    "            mse_[str(w)] = mse_shuff_acc\n",
    "        \n",
    "        if (iterations%25)==0:\n",
    "            print (iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Metrics\n",
      "R2 0.8882798308339088 MAE 2.4386030483458137 MSE 44.11033246713216\n"
     ]
    }
   ],
   "source": [
    "print('Normal Metrics')\n",
    "print('R2',r2_acc,'MAE',mae_acc,'MSE',mse_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features scores, sorted:\n",
      "\n",
      "[(3.3412, 'number_native_genes_overexp'), (3.4653, 'mw_Lipids'), (3.4719, 'TCA_iYLI647'), (3.5408, 'FermentationTime'), (3.5851, 'number_genes_het'), (3.7023, 'precursorsRequiredEncoded'), (3.7126, 'pH'), (3.7812, 'nadh_nadph_cost'), (3.8677, 'rxt_volume'), (3.9937, 'foldCarbonFed'), (4.0428, 'media'), (4.0682, 'product_deltaGo'), (4.1259, 'atp_cost'), (4.2234, 'averageThermBarrier'), (4.2415, 'PrdtYield_iYLI647'), (4.3509, 'product_name'), (4.3669, 'NADPH_iYLI647'), (4.4422, 'Pathway_enzymatic_steps'), (4.5654, 'ATP_iYLI647'), (5.2153, 'inputThermo(kJ/L)'), (5.2479, 'PPP_iYLI647')]\n"
     ]
    }
   ],
   "source": [
    "test = (sorted([(round(np.mean(score), 4), feat) for feat, score in mae_.items()], reverse=False))\n",
    "print('features scores, sorted:\\n')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaPY36",
   "language": "python",
   "name": "condapy36lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
